{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9zb9UW2X2cFaFlSm+mBfw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipecasali-usp/mba-tcc-identify-lgpdsensitive-data/blob/main/CPF_SpaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDpHJjtGHOvp",
        "outputId": "79f00686-c6db-4953-9425-195c36a05ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv('/content/sample_data/empregados_m.csv')\n",
        "\n",
        "# Define a regular expression to identify CPF numbers\n",
        "cpf_regex = r'\\b\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2}\\b'\n",
        "\n",
        "# Prepare training data with examples of annotated text\n",
        "TRAIN_DATA = []\n",
        "\n",
        "# Iterate through each row of the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    # Concatenate all values in the row into a single string\n",
        "    row_text = ' '.join(map(str, row.values))\n",
        "\n",
        "    # Search for CPF numbers using the regular expression\n",
        "    cpf_matches = re.findall(cpf_regex, row_text)\n",
        "\n",
        "    # Annotate the position of CPF numbers\n",
        "    if cpf_matches:\n",
        "        start = row_text.find(cpf_matches[0])\n",
        "        end = start + len(cpf_matches[0])\n",
        "        entities = [(start, end, \"CPF\")]\n",
        "    else:\n",
        "        entities = []\n",
        "\n",
        "    # Add the annotated example to the training data\n",
        "    TRAIN_DATA.append((row_text, {\"entities\": entities}))\n",
        "\n",
        "# Output the annotated data\n",
        "print(TRAIN_DATA)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "from spacy.training.example import Example\n",
        "\n",
        "# Load a blank English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Add the NER pipeline component\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "\n",
        "# Define your entity label\n",
        "ner.add_label(\"SSN\")\n",
        "\n",
        "# Start the training process\n",
        "nlp.begin_training()\n",
        "\n",
        "# Train for a number of iterations\n",
        "for itn in range(20):\n",
        "    # Shuffle the training data\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "\n",
        "    # Create batches and train the model\n",
        "    for batch in spacy.util.minibatch(TRAIN_DATA, size=2):\n",
        "        texts, annotations = zip(*batch)\n",
        "        example = []\n",
        "        # Update the model with the current batch\n",
        "        for i in range(len(texts)):\n",
        "            doc = nlp.make_doc(texts[i])\n",
        "            example.append(Example.from_dict(doc, annotations[i]))\n",
        "        nlp.update(example, losses=losses)\n",
        "    print(\"Iteration:\", itn, \"Losses:\", losses)\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"ssn_ner_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8OTeCqaI5Os",
        "outputId": "7f83fdcb-c03a-41cf-bd75-f009260613fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 Losses: {'ner': 826.5058272229269}\n",
            "Iteration: 1 Losses: {'ner': 7.796192319582059e-11}\n",
            "Iteration: 2 Losses: {'ner': 3.487956603800758e-15}\n",
            "Iteration: 3 Losses: {'ner': 2.09136662085791e-17}\n",
            "Iteration: 4 Losses: {'ner': 3.6408721432834087e-16}\n",
            "Iteration: 5 Losses: {'ner': 1.8490647134956856e-17}\n",
            "Iteration: 6 Losses: {'ner': 2.441915775543297e-16}\n",
            "Iteration: 7 Losses: {'ner': 5.982679088363775e-17}\n",
            "Iteration: 8 Losses: {'ner': 1.1032500517476287e-16}\n",
            "Iteration: 9 Losses: {'ner': 1.4598413199724418e-16}\n",
            "Iteration: 10 Losses: {'ner': 2.6977667809849795e-16}\n",
            "Iteration: 11 Losses: {'ner': 8.667267534035975e-17}\n",
            "Iteration: 12 Losses: {'ner': 6.766589634309798e-17}\n",
            "Iteration: 13 Losses: {'ner': 1.1025064108034637e-16}\n",
            "Iteration: 14 Losses: {'ner': 5.185695818649276e-17}\n",
            "Iteration: 15 Losses: {'ner': 4.3176444655833144e-17}\n",
            "Iteration: 16 Losses: {'ner': 4.6071608035357966e-17}\n",
            "Iteration: 17 Losses: {'ner': 3.747026258190429e-17}\n",
            "Iteration: 18 Losses: {'ner': 5.673759995712206e-17}\n",
            "Iteration: 19 Losses: {'ner': 2.2662494246452233e-16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the saved model\n",
        "nlp = spacy.load(\"ssn_ner_model\")\n",
        "\n",
        "# Example text for testing\n",
        "test_text = \"O meu número de CPF é 282.503.128-30\"\n",
        "\n",
        "# Process the text using the loaded model\n",
        "doc = nlp(test_text)\n",
        "\n",
        "# Print detected entities\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXZEsPsuXglw",
        "outputId": "98e1002b-2ef7-45a6-b7c8-56f4787fcbce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "282.503.128-30 CPF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the saved model\n",
        "nlp = spacy.load(\"ssn_ner_model\")\n",
        "\n",
        "# List of test sentences\n",
        "test_sentences = [\n",
        "    \"Felipe Casali's identification number is 297.222.108-09\",\n",
        "    \"Her wife document is 282.555.128-30\",\n",
        "    \"His RG is 30.746.719-3\"\n",
        "]\n",
        "\n",
        "# Process each test sentence using the loaded model\n",
        "for test_sentence in test_sentences:\n",
        "    doc = nlp(test_sentence)\n",
        "    print(\"Test Sentence:\", test_sentence)\n",
        "    if not doc.ents:\n",
        "        print(\"No entities found.\")\n",
        "    else:\n",
        "        # Print detected entities\n",
        "        for ent in doc.ents:\n",
        "            print(ent.text, ent.label_)\n",
        "    print()  # Empty line for readability between sentences\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yOrxH__YP_I",
        "outputId": "43eb4e6d-9764-4176-acec-71b8c602b963"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Sentence: Felipe Casali's identification number is 297.222.108-09\n",
            "297.222.108-09 CPF\n",
            "\n",
            "Test Sentence: Her wife document is 282.555.128-30\n",
            "282.555.128-30 CPF\n",
            "\n",
            "Test Sentence: His RG is 30.746.719-3\n",
            "No entities found.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}